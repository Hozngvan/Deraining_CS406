import streamlit as st
import os
import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
import torchvision.transforms.functional as TF
# from io import BytesIO
# import glob
from skimage.metrics import peak_signal_noise_ratio as psnr_metric
from skimage.metrics import structural_similarity as ssim_metric

# --- IMPORT ARCHITECTURES ---
from MPRNet import MPRNet 
from PReNet import PReNet
from DRT import DRT_Inference_Wrapper 

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Multi-Model Deraining Comparison", layout="wide", page_icon="üåßÔ∏è")

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ƒê∆Ø·ªúNG D·∫™N DATASET
DATASET_PATH = "./../Test1200/Test1200" 

# DANH S√ÅCH MODELS
MODEL_CONFIGS = {
    "MPRNet": {
        "path": "./pretrained_models/model_epoch_80.pth", 
        "class": MPRNet,
        "args": {},
        "pad_factor": 8
    },
    "PReNet": {
        "path": "./pretrained_models/prenet_best_final.pth", 
        "class": PReNet,
        "args": {"recurrent_iter": 6, "use_GPU": torch.cuda.is_available()},
        "pad_factor": 8
    },
    "DRT (Transformer)": {
        "path": "./pretrained_models/best_model_from_scratch.pt", 
        "class": DRT_Inference_Wrapper,
        "args": {
            "dim": 96, 
            "patch_size": 1, 
            "l_recursion": 3,   
            "n_RTB": 6,         
            "num_heads": 2,     
            "window_size": 7   
        },
        "pad_factor": 7
    }
}

# --- H√ÄM LOAD 1 MODEL  ---
def load_single_model(name, config):
    print(f"Loading {name}...")
    model = config["class"](**config["args"])
    weight_path = config["path"]
    
    if not os.path.exists(weight_path):
        return None, f"File not found: {weight_path}"

    try:
        checkpoint = torch.load(weight_path, map_location=DEVICE)
        
        if name == "PReNet":
            if "model_state" in checkpoint:
                model.load_state_dict(checkpoint["model_state"])
            else:
                model.load_state_dict(checkpoint)
        # ==============================================================
        else:
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint

            new_state_dict = {}
            for k, v in state_dict.items():
                key_name = k[7:] if k.startswith('module.') else k
                new_state_dict[key_name] = v
            
            model.load_state_dict(new_state_dict, strict=False)
            
        model.to(DEVICE)
        model.eval()
        return model, None
    except Exception as e:
        return None, str(e)

# --- H√ÄM LOAD T·∫§T C·∫¢ MODEL ---
@st.cache_resource
def load_all_models():
    loaded_models = {}
    errors = []
    for name, config in MODEL_CONFIGS.items():
        model, err = load_single_model(name, config)
        if model:
            loaded_models[name] = model
        else:
            errors.append(f"{name}: {err}")
    return loaded_models, errors

# --- H√ÄM T√çNH METRICS ---
def calculate_metrics(target_pil, output_pil):
    target_np = np.array(target_pil)
    output_np = np.array(output_pil)
    psnr_val = psnr_metric(target_np, output_np, data_range=255)
    ssim_val = ssim_metric(target_np, output_np, channel_axis=2, data_range=255)
    return psnr_val, ssim_val

# --- H√ÄM X·ª¨ L√ù ·∫¢NH (GI·ªÆ NGUY√äN LOGIC PADDING) ---
def process_image(image_pil, model, model_name):
    config = MODEL_CONFIGS.get(model_name)
    factor = config["pad_factor"] if config else 8

    # Pre-processing
    img = TF.to_tensor(image_pil).to(DEVICE).unsqueeze(0) # BCHW

    # Padding
    h, w = img.shape[2], img.shape[3]
    H, W = ((h + factor) // factor) * factor, ((w + factor) // factor) * factor
    padh, padw = H - h, W - w
    img_padded = F.pad(img, (0, padw, 0, padh), 'reflect')

    # Inference
    with torch.no_grad():
        if "MPRNet" in model_name:
            restored = model(img_padded)[0]
        elif "PReNet" in model_name:
            restored, _ = model(img_padded)
        elif "DRT" in model_name:
            restored = model(img_padded)
        else:
            restored = model(img_padded)
            if isinstance(restored, (list, tuple)): restored = restored[0]

    # Post-processing
    restored = restored[:, :, :h, :w]
    restored = torch.clamp(restored, 0, 1)
    restored = restored.squeeze(0).permute(1, 2, 0).cpu().numpy()
    
    return Image.fromarray((restored * 255).astype(np.uint8))

# --- GIAO DI·ªÜN CH√çNH  ---
st.title("Multi-Model Deraining Comparison")

# Load models
with st.spinner("ƒêang t·∫£i c√°c model v√†o b·ªô nh·ªõ..."):
    models_dict, load_errors = load_all_models()

if load_errors:
    for err in load_errors:
        st.warning(f"Warning: {err}")

if not models_dict:
    st.error("Kh√¥ng c√≥ model n√†o ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
    st.stop()

# --- T·∫†O TABS ---
tab1, tab2 = st.tabs(["ƒê√°nh gi√° tr√™n t·∫≠p Test100", "Upload ·∫£nh ngo√†i"])

# TAB 1
with tab1:
    st.header("ƒê√°nh gi√° hi·ªáu nƒÉng tr√™n t·∫≠p d·ªØ li·ªáu c√≥ ground truth")
    input_dir = os.path.join(DATASET_PATH, "input")
    target_dir = os.path.join(DATASET_PATH, "target")
    
    if not os.path.exists(input_dir) or not os.path.exists(target_dir):
        st.error(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c dataset: `{input_dir}`")
    else:
        image_files = sorted(os.listdir(input_dir))
        image_files = [f for f in image_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if len(image_files) == 0:
            st.warning("Th∆∞ m·ª•c input tr·ªëng.")
        else:
            selected_file = st.selectbox("Ch·ªçn ·∫£nh ƒë·ªÉ test:", image_files)
            input_path = os.path.join(input_dir, selected_file)
            target_path = os.path.join(target_dir, selected_file)
            
            if os.path.exists(target_path):
                col_in, col_gt = st.columns(2)
                input_img = Image.open(input_path).convert("RGB")
                target_img = Image.open(target_path).convert("RGB")
                
                with col_in:
                    st.image(input_img, caption="Rainy Input", use_container_width=False)
                with col_gt:
                    st.image(target_img, caption="Ground Truth (Target)", use_container_width=False)
                
                if st.button("Ch·∫°y ƒê√°nh Gi√°", key="btn_eval"):
                    st.divider()
                    st.subheader("K·∫øt qu·∫£ so s√°nh")
                    cols = st.columns(len(models_dict))
                    
                    for idx, (name, model) in enumerate(models_dict.items()):
                        with cols[idx]:
                            with st.spinner(f"Running {name}..."):
                                try:
                                    output_img = process_image(input_img, model, name)
                                    psnr, ssim = calculate_metrics(target_img, output_img)
                                    st.image(output_img, caption=f"Output: {name}", use_container_width=True)
                                    st.success(f"**PSNR:** {psnr:.2f} dB\n\n**SSIM:** {ssim:.4f}")
                                except Exception as e:
                                    st.error(f"L·ªói {name}: {e}")
            else:
                st.error(f"Kh√¥ng t√¨m th·∫•y file Ground Truth: `{target_path}`")

# TAB 2
with tab2:
    st.header("Ch·∫°y th·ª≠ tr√™n ·∫£nh t·∫£i l√™n")
    uploaded_file = st.file_uploader("Upload ·∫£nh ƒë·∫ßu v√†o...", type=["jpg", "png", "jpeg"])

    if uploaded_file:
        input_image = Image.open(uploaded_file).convert("RGB")
        st.subheader("·∫¢nh G·ªëc (Input)")
        st.image(input_image, use_container_width=True)

        if st.button("Ch·∫°y So S√°nh T·∫•t C·∫£ Model", key="btn_inference"):
            st.divider()
            st.subheader("K·∫øt Qu·∫£")
            cols = st.columns(len(models_dict))
            for idx, (name, model) in enumerate(models_dict.items()):
                with cols[idx]:
                    st.info(f"**{name}**")
                    try:
                        output = process_image(input_image, model, name)
                        st.image(output, caption=f"Output: {name}", use_container_width=True)
                    except Exception as e:
                        st.error(f"L·ªói: {e}")

st.sidebar.divider()
st.sidebar.info("H·ªá th·ªëng h·ªó tr·ª£ 2 ch·∫ø ƒë·ªô:\n1. **Benchmark**: So s√°nh v·ªõi Ground Truth.\n2. **Inference**: Ch·∫°y th·ª±c t·∫ø.")